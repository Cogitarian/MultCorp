{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0fHzlSD6RLx8Q1oAPOfup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cogitarian/MultCorp/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usługa Whisper jest nowa i zapewne będzie jeszcze wielokrotnie aktualizowana, więc niniejsza procedura transkrypcji nagrań zmieni się, prawdopodobnie powstaną aplikacje do transkrypcji, które nie będą wymagały używania wiersza poleceń. Aktualnie, pod koniec 2023 roku, mamy dostęp do Whispera głównie przez wiersz poleceń lub przez programowanie w Pythonie.\n",
        "1.\tW celu wywołania Whispera musimy zainstalować Chocolatey, Conda, Python, ffmpeg, CUDA, Pytorch. Na szczęście w Internecie znajdziemy skrypty, które wykonają instalację za nas ."
      ],
      "metadata": {
        "id": "eXp_wSvsBMhg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8WPFKLjAo1M"
      },
      "outputs": [],
      "source": [
        "# Copyright (C) 2023 TroubleChute (Wesley Pyburn)\n",
        "# Licensed under the GNU General Public License v3.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.gnu.org/licenses/gpl-3.0.en.html\n",
        "#\n",
        "#    This program is free software: you can redistribute it and/or modify\n",
        "#    it under the terms of the GNU General Public License as published by\n",
        "#    the Free Software Foundation, either version 3 of the License, or\n",
        "#    (at your option) any later version.\n",
        "#\n",
        "#    This program is distributed in the hope that it will be useful,\n",
        "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "#    GNU General Public License for more details.\n",
        "#\n",
        "#    You should have received a copy of the GNU General Public License\n",
        "#    along with this program.  If not, see .\n",
        "#\n",
        "# ----------------------------------------\n",
        "# This script:\n",
        "# 1. Installs Chocolatey (for installing Python and FFMPEG) - https://chocolatey.org/install\n",
        "# 2. Check if Conda or Python is installed. If neither: install Python using Choco (if Python not already detected)\n",
        "# 3. Installs FFMPEG using Choco (if FFMPEG not already detected)\n",
        "# 4. Install CUDA using Choco (if CUDA not already detected)\n",
        "# 5. Install Pytorch if not already installed, or update. Installs either GPU version if CUDA found, or CPU-only version\n",
        "# 6. Verify that Whisper is installed. Reinstall using another method if not.\n",
        "# ----------------------------------------\n",
        "\n",
        "Write-Host \"--------------------------------------------\" -ForegroundColor Cyan\n",
        "Write-Host \"Welcome to TroubleChute's Whisper installer!\" -ForegroundColor Cyan\n",
        "Write-Host \"Whisper as well as all of its other dependencies should now be installed...\" -ForegroundColor Cyan\n",
        "Write-Host \"[Version 2023-06-06]\" -ForegroundColor Cyan\n",
        "Write-Host \"`nThis script is provided AS-IS without warranty of any kind. See https://tc.ht/privacy & https://tc.ht/terms.\"\n",
        "Write-Host \"Consider supporting these install scripts: https://tc.ht/support\" -ForegroundColor Green\n",
        "Write-Host \"--------------------------------------------`n`n\" -ForegroundColor Cyan\n",
        "\n",
        "Set-Variable ProgressPreference SilentlyContinue # Remove annoying yellow progress bars when doing Invoke-WebRequest for this session\n",
        "\n",
        "# 1. Install Chocolatey\n",
        "Write-Host \"`nInstalling Chocolatey...\" -ForegroundColor Cyan\n",
        "Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n",
        "\n",
        "# Import function to reload without needing to re-open Powershell\n",
        "iex (irm refreshenv.tc.ht)\n",
        "\n",
        "# 2. Check if Conda or Python is installed\n",
        "# Check if Conda is installed\n",
        "Import-FunctionIfNotExists -Command Get-UseConda -ScriptUri \"Get-Python.tc.ht\"\n",
        "# Check if Conda is installed\n",
        "$condaFound = Get-UseConda -Name \"Whisper\" -EnvName \"whisper\" -PythonVersion \"3.10.11\"\n",
        "# Get Python command (eg. python, python3) & Check for compatible version\n",
        "if ($condaFound) {\n",
        "    conda activate \"whisper\"\n",
        "    $python = \"python\"\n",
        "} else {\n",
        "    $python = Get-Python -PythonRegex 'Python ([3].[1][0-1].[6-9]|3.10.1[0-1])' -PythonRegexExplanation \"Python version is not between 3.10.6 and 3.10.11.\" -PythonInstallVersion \"3.10.11\" -ManualInstallGuide \"https://hub.tcno.co/ai/whisper/install/\"\n",
        "    if ($python -eq \"miniconda\") {\n",
        "        $python = \"python\"\n",
        "        $condaFound = $true\n",
        "    }\n",
        "}\n",
        "# 3. Install FFMPEG with Choco if not already installed.\n",
        "if (-not (Get-Command ffmpeg -ErrorAction SilentlyContinue)) {\n",
        "    Write-Host \"`nFFMPEG is not installed. Installing...\" -ForegroundColor Cyan\n",
        "    choco upgrade ffmpeg -y\n",
        "    Update-SessionEnvironment\n",
        "}\n",
        "if (Get-Command ffmpeg -ErrorAction SilentlyContinue) {\n",
        "    Write-Host \"FFmpeg is installed.\" -ForegroundColor Green\n",
        "}\n",
        "else {\n",
        "    Write-Host \"FFmpeg is not installed. Please add FFMPEG to PATH (install ffmpeg) and run this script again.\" -ForegroundColor Red\n",
        "    Write-Host \"Alternatively, follow this guide for manual installation: https://hub.tcno.co/ai/whisper/install/\" -ForegroundColor Red\n",
        "    Read-Host \"Process can not continue. The program will exit when you press Enter to continue...\"\n",
        "    Exit\n",
        "}\n",
        "iex (irm Import-RemoteFunction.tc.ht)\n",
        "# 4. Install CUDA using Choco if not already installed.\n",
        "if ((Get-CimInstance Win32_VideoController).Name -like \"*Nvidia*\") {\n",
        "    Import-FunctionIfNotExists -Command Install-CudaAndcuDNN -ScriptUri \"Install-Cuda.tc.ht\"\n",
        "    Install-CudaAndcuDNN -CudaVersion \"11.8\" -CudnnOptional $true\n",
        "\n",
        "    # 5. Install Pytorch if not already installed, or update.\n",
        "    Write-Host \"`nInstalling or updating PyTorch (With GPU support)...\" -ForegroundColor Cyan\n",
        "    if ($condaFound){\n",
        "        conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
        "    } else {\n",
        "        &$python -m pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "    }\n",
        "} else {\n",
        "    Write-Host \"Nvidia CUDA is not installed. Please install the latest Nvidia CUDA Toolkit and run this script again.\" -ForegroundColor Red\n",
        "    Write-Host \"For now the script will proceed with installing CPU-only PyTorch. Whisper will still run when it's done.\" -ForegroundColor Red\n",
        "\n",
        "    # 5. Install Pytorch if not already installed, or update.\n",
        "    Write-Host \"`nInstalling or updating PyTorch (CPU-only)...\" -ForegroundColor Cyan\n",
        "    if ($condaFound) {\n",
        "        conda install pytorch torchvision torchaudio cpuonly -c pytorch -y\n",
        "    } else {\n",
        "        &$python -m pip install torch torchvision torchaudio\n",
        "    }\n",
        "}\n",
        "Write-Host \"`nInstalling or updating Whisper...\" -ForegroundColor Cyan\n",
        "if ($condaFound) {\n",
        "    # For some reason conda NEEDS to be deactivated and reactivated to use pip reliably... Otherwise python and pip are not found.\n",
        "    conda deactivate\n",
        "    #Open-Conda\n",
        "    conda activate whisper\n",
        "    pip install -U openai-whisper # Environment is already active\n",
        "} else {\n",
        "    &$python -m pip install -U openai-whisper\n",
        "    Update-SessionEnvironment\n",
        "}\n",
        "# 6. Verify that Whisper is installed. Reinstall using another method if not.\n",
        "if (Get-Command whisper -ErrorAction SilentlyContinue) {\n",
        "    Write-Host \"`n`nWhisper is installed!\" -ForegroundColor Green\n",
        "    Write-Host \"You can now use `whisper --help` for more information in this PowerShell window, CMD or another program!\" -ForegroundColor Green\n",
        "}\n",
        "else {\n",
        "    Write-Host \"Whisper is not installed, trying again but this time installing from the openai/whisper GitHub repo\" -ForegroundColor Green\n",
        "\n",
        "    if ($condaFound){\n",
        "        pip install -U setuptools-rust\n",
        "        pip install git+https://github.com/openai/whisper.git\n",
        "    } else {\n",
        "        &$python -m pip install -U setuptools-rust\n",
        "        &$python -m pip install -U --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n",
        "    }\n",
        "\n",
        "    if (Get-Command whisper -ErrorAction SilentlyContinue) {\n",
        "        Write-Host \"`n`nWhisper is installed!\" -ForegroundColor Green\n",
        "        Write-Host \"You can now use whisper --help for more information in this PowerShell window, CMD or another program!\" -ForegroundColor Green\n",
        "    } else {\n",
        "        Write-Host \"`n`nWhisper is not installed. Please follow this guide for manual installation: https://hub.tcno.co/ai/whisper/install/\" -ForegroundColor Red\n",
        "        Read-Host \"Process can not continue. The program will exit when you press Enter to continue...\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2.\tPliki dźwiękowe przed transkrypcją dzielimy na mniejsze, bo wówczas transkrypcja będzie sprawniejsza i serwis nie ulegnie przepełnieniu.\n"
      ],
      "metadata": {
        "id": "Gn2IAVY9BVT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ffmpeg -i input.wav segment -segment_time 10:00 output%02d.wav"
      ],
      "metadata": {
        "id": "mhc3LYwZBctp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tPliki dźwiękowe konwertujemy do formatu 16 kHz:"
      ],
      "metadata": {
        "id": "ouWp7Lh-Bdnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ffmpeg -i input.wav -ac 1 -ar 16000 output-16k.wav"
      ],
      "metadata": {
        "id": "U9ildtuSB2PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a w pętli dla wszystkich plików w katalogu:"
      ],
      "metadata": {
        "id": "mK-JC0s7B3Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in *.wav; do ffmpeg -i $f -ac 1 -ar 16000 $f-16k.wav; done;"
      ],
      "metadata": {
        "id": "PahRlfjTB80d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\tWhisper ma wiele parametrów i trybów pracy, więc ograniczymy się do komendy inicjującej transkrypcję nagrań w języku polskim. Do transkrypcji polskiego potrzebny jest duży model językowy ggml-large.bin."
      ],
      "metadata": {
        "id": "ragKdhgXCA73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set model = large curl – L\n",
        "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-%model%.bin –o models\\ggml-%model %.bin"
      ],
      "metadata": {
        "id": "nthq1Rq9CEKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\tI wreszcie możemy uruchomić transkrypcję:"
      ],
      "metadata": {
        "id": "lMStuVtUCIDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "./main -l pl -m models/ggml-large.bin -f samples/input.wav >output.txt"
      ],
      "metadata": {
        "id": "AByQZMaECHQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " w pętli dla wszystkich plików w katalogu:"
      ],
      "metadata": {
        "id": "M8nNoIwwCNHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in /ścieżka/16k/*.wav; do ./main -t 8 -l pl -m models/ggml-large.bin -f $f -otxt -ps -pp -pc; done;"
      ],
      "metadata": {
        "id": "H36-fmu9COHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zamiast ścieżka należy wpisać ścieżkę do katalogu z plikami dźwiękowymi w formacie 16 kHz. W przypadku innej procedury instalacji ./main zamieniamy na whisper. Dostępne są także usługi przekładu. Dostęp programistyczny do Whispera w Pythonie :\n"
      ],
      "metadata": {
        "id": "13Lza9n6CT5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "# whisper has multiple models that you can load as per size and requirements\n",
        "model = whisper.load_model(\"small.en\")\n",
        "# path to the audio file you want to transcribe\n",
        "PATH = \"audio.mp3\"\n",
        "result = model.transcribe(PATH)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "KPZ95X36CYfl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}